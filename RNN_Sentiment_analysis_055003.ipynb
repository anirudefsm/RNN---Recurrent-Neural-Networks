{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eItXrdXXGgtP"
   },
   "source": [
    "# Sentiment Analysis Using Recurrent Neural Networks (RNNs)\n",
    "\n",
    "**Submitted by:**  \n",
    "\n",
    "Anirudh Gupta (055003)\n",
    "\n",
    "Amitanshu Tiwari (055054)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Title  \n",
    "**Sentiment Analysis Using Recurrent Neural Networks (RNNs)**\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Problem Statement\n",
    "\n",
    "With the exponential growth of user-generated content, organizations must leverage automated tools to extract sentiment insights from large volumes of text, such as customer reviews and feedback. While machine learning offers promising capabilities, many models trained on standardized datasets fail to generalize across platforms due to differences in writing style, tone, and vocabulary.\n",
    "\n",
    "**Core Challenge:**  \n",
    "How can a sentiment classification model be trained to not only perform well on a known dataset (IMDB) but also generalize effectively to an unseen, real-world dataset (Metacritic reviews)?\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Objectives\n",
    "\n",
    "- Build and train an RNN model for binary sentiment classification on the IMDB dataset.\n",
    "- Optimize the model using hyperparameter tuning and regularization techniques.\n",
    "- Evaluate model generalization on an external dataset.\n",
    "- Compare the performance of different RNN architectures.\n",
    "- Provide insights and recommendations based on model behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Dataset Information\n",
    "\n",
    "### 4.1 IMDB Dataset\n",
    "- 50,000 labeled movie reviews (balanced: positive/negative).\n",
    "- Preprocessing included:\n",
    "  - HTML tag removal and text cleaning.\n",
    "  - Tokenization (vocabulary size: 20,000).\n",
    "  - Padding to fixed sequence length (200).\n",
    "  - Binary encoding of sentiment labels (positive: 1, negative: 0).\n",
    "\n",
    "### 4.2 External Dataset\n",
    "- Reviews collected from Metacritic (downloaded via Google Drive).\n",
    "- Used as an unseen test set to evaluate model generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Model Architectures\n",
    "\n",
    "### 5.1 Baseline RNN\n",
    "- **Embedding Layer**: 50 dimensions, input length 200.\n",
    "- **SimpleRNN Layer**: 128 units with ReLU activation.\n",
    "- **Dense Output Layer**: Sigmoid activation for binary classification.\n",
    "- **Optimizer**: Adam.\n",
    "- **Loss**: Binary Crossentropy.\n",
    "\n",
    "### 5.2 Tuned RNN\n",
    "- **Embedding Layer**: 128 dimensions (tuned).\n",
    "- **SimpleRNN Layer**: 128 units (tuned).\n",
    "- **Dropout**: 0.2 (tuned).\n",
    "- **Learning Rate**: 0.0001 (tuned).\n",
    "- **EarlyStopping and ModelCheckpoint** for optimization.\n",
    "\n",
    "### 5.3 Bidirectional RNN\n",
    "- **Bidirectional(SimpleRNN)** layer to capture forward and backward context.\n",
    "- **Gradient clipping** for stability.\n",
    "- **L2 Regularization** to prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Training Details\n",
    "\n",
    "- **Epochs**: 10 to 30 (with early stopping).  \n",
    "- **Batch Size**: 64.  \n",
    "- **Data Split**: 60% training, 40% testing (stratified).  \n",
    "- **Hyperparameter Tuning**: Conducted using Keras Tuner.  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Evaluation Metrics\n",
    "\n",
    "### 7.1 Performance on IMDB Dataset\n",
    "\n",
    "| Model              | Training Accuracy | Validation Accuracy | Test Accuracy |\n",
    "|-------------------|-------------------|---------------------|---------------|\n",
    "| Basic RNN         | ~100%             | ~100%               | 100%          |\n",
    "| Tuned RNN         | ~50%              | ~50%                | 50%           |\n",
    "| Bidirectional RNN | ~50%              | ~50%                | 50%           |\n",
    "\n",
    "### 7.2 Performance on External Dataset\n",
    "\n",
    "| Model              | External Accuracy |\n",
    "|-------------------|-------------------|\n",
    "| Basic RNN         | 48.33%            |\n",
    "| Tuned RNN         | 43.33%            |\n",
    "| Bidirectional RNN | 43.33%            |\n",
    "\n",
    "- **Confusion matrices** showed that models struggled with negative reviews, often misclassifying them as positive.\n",
    "- **Precision and recall** were notably lower for negative sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Observations\n",
    "\n",
    "- **Overfitting**: The Basic RNN achieved 100% accuracy on the IMDB dataset but performed poorly on external data, indicating severe overfitting.\n",
    "- **Hyperparameter Tuning**: The Tuned RNN and Bidirectional RNN showed no significant improvement, suggesting limitations in RNN architectures for this task.\n",
    "- **Generalization Gap**: All models failed to generalize well to the Metacritic dataset, highlighting the need for more robust architectures.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Conclusion\n",
    "\n",
    "- The Basic RNN achieved perfect accuracy on the IMDB dataset but failed to generalize to external data, indicating overfitting.\n",
    "- Hyperparameter tuning and Bidirectional RNNs did not improve performance, suggesting that simple RNNs are insufficient for robust sentiment analysis.\n",
    "- The models exhibited a bias toward positive sentiment classification, likely due to dataset imbalances or inherent limitations in RNNs.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Managerial Insights\n",
    "\n",
    "### Insight 1: RNNs Alone Are Not Sufficient for Real-World Applications\n",
    "While RNNs can achieve high accuracy on benchmark datasets, they often fail to generalize to real-world data. Businesses should explore advanced architectures like LSTMs, GRUs, or transformer-based models (e.g., BERT) for reliable sentiment analysis.\n",
    "\n",
    "### Insight 2: Overfitting is a Major Challenge\n",
    "The 100% training accuracy on IMDB data contrasted sharply with poor external performance, underscoring the need for robust validation and external testing.\n",
    "\n",
    "### Insight 3: Model Complexity Does Not Always Help\n",
    "Tuning and adding Bidirectional layers did not improve generalization, indicating that more complex models are not always better for this task.\n",
    "\n",
    "### Insight 4: Generalization is Critical for Business Value\n",
    "Models must perform consistently across diverse datasets to provide actionable insights. Without generalization, business decisions based on model outputs may be flawed.\n",
    "\n",
    "### Insight 5: Strategic Recommendations\n",
    "- **Adopt Advanced Architectures**: Use LSTMs, GRUs, or transformers for better performance.\n",
    "- **Fine-Tune on Domain-Specific Data**: Train models on internal datasets to improve relevance.\n",
    "- **Monitor and Retrain**: Continuously evaluate models on new data to ensure ongoing accuracy.\n",
    "- **Balance Datasets**: Address class imbalances to reduce bias in predictions.\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F21nDLzNXJcJ"
   },
   "source": [
    "# Importing Libraries for handling Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MIPH8USK7KCT"
   },
   "outputs": [],
   "source": [
    "# for string matching\n",
    "import re\n",
    "\n",
    "# for reading data\n",
    "import pandas as pd\n",
    "\n",
    "# for handling html data\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwHfiXRmXSXY"
   },
   "source": [
    "# Loading IMDB Text Dataset for traning and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9feb6vU874VC",
    "outputId": "18fda376-be41-425c-9770-f95d2cfb09bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film was a complete disappointment. Poor script and weak acting.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brilliant storytelling and direction. One of the best movies I've seen this year.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was absolutely fantastic! The plot was gripping from start to finish.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The storyline made no sense and the characters were unconvincing.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I struggled to stay awake. It was that boring.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              review  \\\n",
       "0              This film was a complete disappointment. Poor script and weak acting.   \n",
       "1  Brilliant storytelling and direction. One of the best movies I've seen this year.   \n",
       "2   This movie was absolutely fantastic! The plot was gripping from start to finish.   \n",
       "3                  The storyline made no sense and the characters were unconvincing.   \n",
       "4                                     I struggled to stay awake. It was that boring.   \n",
       "\n",
       "  sentiment  \n",
       "0  negative  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Replace with your actual file ID\n",
    "file_id = '1zjniZSXMi3oaOqs7ZeRyqWW3O6dRr8Wf'\n",
    "\n",
    "# Construct the URL\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Fetch the data using requests\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an exception for bad responses\n",
    "\n",
    "# Read the data into a pandas DataFrame using StringIO\n",
    "imdb = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grr8zZYb5LMN",
    "outputId": "cc9f4598-c6d6-49e9-de93-9ad8522618f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhmymAc99ICO"
   },
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I8uPZ_Zm9JDE"
   },
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "\n",
    "  # take off html tags\n",
    "  text = BeautifulSoup(text).get_text()\n",
    "\n",
    "  # fetch alphabetic characters\n",
    "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "  # convert text to lower case\n",
    "  text = text.lower()\n",
    "\n",
    "  # split text into tokens to remove whitespaces\n",
    "  tokens = text.split()\n",
    "\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rx6R_5D09Lt0"
   },
   "outputs": [],
   "source": [
    "# call preprocessing function\n",
    "imdb['cleaned_text'] = imdb['review'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "aPMY_bzg9cof",
    "outputId": "544f567b-9bdb-4c56-b58e-a4e9b17aeaf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Brilliant storytelling and direction. One of the best movies I've seen this year.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Gw2YCDW59dLb",
    "outputId": "3d60344d-a548-45ea-8553-52bfd23db9d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brilliant storytelling and direction one of the best movies i ve seen this year'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['cleaned_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YZxUNKafAsxN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming 'imdb' is your DataFrame\n",
    "X = imdb['cleaned_text'].values  # Extract cleaned text\n",
    "y = imdb['sentiment'].map({'positive': 1, 'negative': 0}).values  # Convert labels to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UrwfZ5dOAvnc"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=20000)  # Keep 20,000 most frequent words\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "max_len = 200  # Define max length of sequences\n",
    "X_padded = pad_sequences(X_sequences, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkd8j8hnA0eg"
   },
   "source": [
    "# Splitting dataset\n",
    "## Print shapes to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6QYJmb8Dhg2",
    "outputId": "e7491125-6876-471c-99cf-2414271e05a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30000, 200)\n",
      "X_test shape: (20000, 200)\n",
      "y_train shape: (30000,)\n",
      "y_test shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.4,stratify=y, random_state=5403)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cAYfdqcNA5wN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 20000  # Same as in the tokenizer\n",
    "embedding_dim = 128\n",
    "rnn_units = 128\n",
    "max_len=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqdLV24zE3tn",
    "outputId": "0cdc59e7-a15d-400d-dc37-265e1941159c"
   },
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "#sequential model\n",
    "model = Sequential()\n",
    "# Update vocab_size dynamically\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Ensure it matches tokenizer\n",
    "#embedding layer\n",
    "model.add(Embedding(vocab_size, 50, input_shape=(max_len,), mask_zero=True))\n",
    "\n",
    "#rnn layer\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "\n",
    "#dense layer\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "#output layer\n",
    "# Change the number of units to 1 and activation to 'sigmoid'\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "fA7WeAnQFZ9z",
    "outputId": "148f79ff-f955-4934-f569-2021b4533fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 50)           3850      \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               22912     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43403 (169.54 KB)\n",
      "Trainable params: 43403 (169.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnzM4zNKFezu"
   },
   "source": [
    "# Define the optimizer and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KVReYHfKFf01"
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoUdcR-hGeSL"
   },
   "source": [
    "Define a callback - Model Checkpoint. Model Checkpoint is a callback used to save the best model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5Jw37BQ3GfCN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Save the model to a file called 'best_model.h5'\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YoMGARPFkqH"
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "Lets train the model for 10 epochs with a batch size of 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qnDGeZ6FtTt",
    "outputId": "33d03e67-8e2f-42bf-f945-7a80066f0960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9987\n",
      "Epoch 1: val_loss improved from inf to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 47s 97ms/step - loss: 0.0219 - accuracy: 0.9987 - val_loss: 4.5653e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "  1/469 [..............................] - ETA: 38s - loss: 2.2479e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 3.7231e-07 - accuracy: 1.0000\n",
      "Epoch 2: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 46s 97ms/step - loss: 3.7231e-07 - accuracy: 1.0000 - val_loss: 2.6169e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.1636e-07 - accuracy: 1.0000\n",
      "Epoch 3: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 44s 93ms/step - loss: 2.1636e-07 - accuracy: 1.0000 - val_loss: 1.5593e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 1.3224e-07 - accuracy: 1.0000\n",
      "Epoch 4: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 1.3224e-07 - accuracy: 1.0000 - val_loss: 9.7888e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 8.5820e-08 - accuracy: 1.0000\n",
      "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 40s 85ms/step - loss: 8.5820e-08 - accuracy: 1.0000 - val_loss: 6.7949e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 6.2089e-08 - accuracy: 1.0000\n",
      "Epoch 6: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 39s 83ms/step - loss: 6.2089e-08 - accuracy: 1.0000 - val_loss: 4.9670e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 4.5869e-08 - accuracy: 1.0000\n",
      "Epoch 7: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 40s 85ms/step - loss: 4.5869e-08 - accuracy: 1.0000 - val_loss: 3.7233e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 3.4400e-08 - accuracy: 1.0000\n",
      "Epoch 8: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 40s 85ms/step - loss: 3.4400e-08 - accuracy: 1.0000 - val_loss: 2.7982e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.6257e-08 - accuracy: 1.0000\n",
      "Epoch 9: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 2.6257e-08 - accuracy: 1.0000 - val_loss: 2.1644e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.0203e-08 - accuracy: 1.0000\n",
      "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to best_model.h5\n",
      "469/469 [==============================] - 39s 84ms/step - loss: 2.0203e-08 - accuracy: 1.0000 - val_loss: 1.7238e-08 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history=model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test,y_test), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO_jrsQdIvnJ"
   },
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epcDRXq2IvM5",
    "outputId": "caf3b8ef-cc1f-4291-8d63-7960e09d971b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 8s 12ms/step - loss: 1.7238e-08 - accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ar1mEcpOiuq"
   },
   "source": [
    "Accuracy of the model is 100% which is significantly good for testing further. (Note: The accuracy varied a little each time of execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIvAS748JKdY"
   },
   "source": [
    "# Plot the Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "JTYvLOPaJLYt",
    "outputId": "ca93e1ad-038a-458d-c826-ee7ee2c75059"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFlq6O4FOydA"
   },
   "source": [
    "The graphs of accuracy and loss display certain trends. The training loss decreases significantly in the initial epochs and then plateaus near zero. The training accuracy increases sharply in the initial epochs and then plateaus near 1.0000. The validation loss starts high and quickly drops to a very low value, where it remains relatively stable. The validation accuracy also increases rapidly and then plateaus slightly below 1.0000.\n",
    "\n",
    "The small but noticeable gap between the training accuracy (near 1.0000) and the slightly lower validation accuracy (plateauing just below 1.0000) suggests that the model might be starting to overfit the training data. This indicates that while the model performs exceptionally well on the training data, its ability to generalize to unseen data might be slightly compromised.\n",
    "\n",
    "While the potential for overfitting exists, attributing it solely to the limitation of the RNN's short-term memory without further context or analysis might be premature. Overfitting can occur for various reasons, including the model's capacity, the amount of training data, and the complexity of the task. Further investigation would be needed to definitively link this behavior to the RNN's memory limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAbSxBriK5dy"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5b1As7KKoRA",
    "outputId": "8ef54d7c-e8c8-4f2a-e0b7-71d612461bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n",
      "Review: The movie was absolutely fantastic! I loved it.\n",
      "Prediction: 0.8234  Positive\n",
      "------------------------------------------------------------\n",
      "Review: It was the worst film I have ever seen. Total waste of time.\n",
      "Prediction: 0.4408  Negative\n",
      "------------------------------------------------------------\n",
      "Review: The acting was mediocre but the storyline was great.\n",
      "Prediction: 0.0052  Negative\n",
      "------------------------------------------------------------\n",
      "Review: I don't think I'll recommend this product to anyone.\n",
      "Prediction: 0.0016  Negative\n",
      "------------------------------------------------------------\n",
      "Review: Absolutely brilliant! Highly recommended.\n",
      "Prediction: 0.3341  Negative\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Random test samples\n",
    "test_reviews = [\n",
    "    \"The movie was absolutely fantastic! I loved it.\",\n",
    "    \"It was the worst film I have ever seen. Total waste of time.\",\n",
    "    \"The acting was mediocre but the storyline was great.\",\n",
    "    \"I don't think I'll recommend this product to anyone.\",\n",
    "    \"Absolutely brilliant! Highly recommended.\"\n",
    "]\n",
    "\n",
    "# Preprocess the random text\n",
    "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=200, padding='post')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_padded)\n",
    "\n",
    "# Interpret results\n",
    "for i, review in enumerate(test_reviews):\n",
    "    sentiment = \"Positive\" if predictions[i][0] > 0.5 else \"Negative\"\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Prediction: {predictions[i][0]:.4f}  {sentiment}\")\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MyFPw2wQ2XF"
   },
   "source": [
    "We can see that the model could predict 80% of the data accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-30xCEmx798U"
   },
   "source": [
    "# Training on Metacritic reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hcj_rcn781i",
    "outputId": "0ac83ad2-6493-4048-d314-4bad4a5153fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lcNIeBdOHxjbr8i30WrAhnuDqXo84m7Q\n",
      "To: C:\\Users\\aniru\\data.csv\n",
      "100%|| 4.42k/4.42k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Movie  \\\n",
      "0        Inception   \n",
      "1  The Dark Knight   \n",
      "2       La La Land   \n",
      "3             Cats   \n",
      "4    The Godfather   \n",
      "\n",
      "                                                                              Review  \\\n",
      "0          An absolutely mind-bending and thrilling experience. Nolan's masterpiece.   \n",
      "1  Brilliant performance by Heath Ledger. Gripping and intense from start to finish.   \n",
      "2      A heartwarming musical with stellar performances and stunning cinematography.   \n",
      "3                  A complete disaster. Poor CGI, weak plot, and bizarre characters.   \n",
      "4     One of the greatest films of all time. Powerful performances and storytelling.   \n",
      "\n",
      "  Sentiment  \n",
      "0  Positive  \n",
      "1  Positive  \n",
      "2  Positive  \n",
      "3  Negative  \n",
      "4  Positive  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Google Drive file ID\n",
    "file_id = \"1lcNIeBdOHxjbr8i30WrAhnuDqXo84m7Q\"\n",
    "output = \"data.csv\"  # Name to save the file\n",
    "\n",
    "# Construct the direct download URL\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "# Read the CSV file\n",
    "test_data = pd.read_csv(output)\n",
    "\n",
    "# Display the first few rows\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrctgKOZ8MSq"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2n7p1mOQ8DAK"
   },
   "outputs": [],
   "source": [
    "# Apply the same cleaning function\n",
    "test_data['cleaned_text'] = test_data['Review'].apply(cleaner)\n",
    "\n",
    "# Tokenize the text using the same tokenizer\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['cleaned_text'])\n",
    "\n",
    "# Pad the sequences to match the model's input size\n",
    "X_test_padded = pad_sequences(test_sequences, maxlen=200, padding='post')\n",
    "\n",
    "# Map true labels to 0 and 1 for consistency\n",
    "label_mapping = {'Negative': 0, 'Positive': 1}\n",
    "test_data['sentiment_encoded'] = test_data['Sentiment'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0a6XR2m8aEc"
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mByfbPcY8cwj",
    "outputId": "43a93380-58fd-4caa-81f4-4c2eade5b999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "#  Make predictions\n",
    "predictions = model.predict(X_test_padded)\n",
    "\n",
    "#  Convert probabilities to binary labels\n",
    "test_data['predicted_sentiment'] = (predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPFQ1Iyc8lKO"
   },
   "source": [
    "# Evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qULd3lMq8kft",
    "outputId": "bfc15c06-bab3-4883-9cc0-eda95604094f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Accuracy on New Test Data: 0.4833\n",
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.96      0.62        26\n",
      "           1       0.80      0.12      0.21        34\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.63      0.54      0.41        60\n",
      "weighted avg       0.65      0.48      0.38        60\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "\n",
      "[[25  1]\n",
      " [30  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "#  Calculate accuracy\n",
    "accuracy = accuracy_score(test_data['sentiment_encoded'], test_data['predicted_sentiment'])\n",
    "print(f\"\\n Model Accuracy on New Test Data: {accuracy:.4f}\")\n",
    "\n",
    "#  Display a detailed classification report\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(test_data['sentiment_encoded'], test_data['predicted_sentiment']))\n",
    "\n",
    "#  Display confusion matrix\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(test_data['sentiment_encoded'], test_data['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkUbQzXsJPD2"
   },
   "source": [
    "#  **RNN Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tvxlsa8MbF6",
    "outputId": "194d6fef-af13-4026-c114-dc1cc577b040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\aniru\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from keras-tuner) (2.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from keras-tuner) (20.9)\n",
      "Requirement already satisfied: requests in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aniru\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2020.12.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\aniru\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "#Using KerasTuner for Automated Hyperparameter Tuning\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wre-XRjdMm20"
   },
   "source": [
    "# Tuning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "d4aGX3pyMfOn"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the model-building function\n",
    "def build_model(hp):\n",
    "    model2 = Sequential()\n",
    "\n",
    "    # Hyperparameter options\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    embedding_dim = hp.Int('embedding_dim', min_value=64, max_value=256, step=64)\n",
    "    rnn_units = hp.Int('rnn_units', min_value=64, max_value=256, step=64)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)\n",
    "\n",
    "    # Model architecture\n",
    "    model2.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=200))\n",
    "\n",
    "    # Use return_sequences=True in the first RNN layer to stack them properly\n",
    "    model2.add(SimpleRNN(units=rnn_units, return_sequences=True))\n",
    "    model2.add(Dropout(dropout_rate))  #  Fixed variable name\n",
    "\n",
    "    model2.add(SimpleRNN(units=rnn_units, return_sequences=False))\n",
    "    model2.add(Dropout(dropout_rate))  #  Fixed variable name\n",
    "\n",
    "    model2.add(Dense(64, activation='relu'))\n",
    "    model2.add(Dropout(dropout_rate))\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.0005, 0.0001])\n",
    "    model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0ooHnhzMtUo",
    "outputId": "9541f1a2-8130-44f7-f5d9-7637e4569d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from rnn_tuning\\imdb_sentiment\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,            # Try 3 different sets of hyperparameters\n",
    "    executions_per_trial=2,  # Run each set twice for stability\n",
    "    directory='rnn_tuning',\n",
    "    project_name='imdb_sentiment'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvTi_FxsM32f",
    "outputId": "ffb93e06-1c0d-404f-dc61-e691069b0e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best Hyperparameters:\n",
      "- Embedding Dim: 128\n",
      "- RNN Units: 64\n",
      "- Dropout Rate: 0.2\n",
      "- Learning Rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=64)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    " Best Hyperparameters:\n",
    "- Embedding Dim: {best_hps.get('embedding_dim')}\n",
    "- RNN Units: {best_hps.get('rnn_units')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNhIk7JwJgE7"
   },
   "source": [
    "# Train the Model with Best Hyperparameters calculated : Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvGcdMEVtGHX",
    "outputId": "8ada268b-d516-4e95-ee14-9714afd6016a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6984 - accuracy: 0.5056\n",
      "Epoch 1: val_loss improved from inf to 0.69381, saving model to final_rnn_sentiment_model_optimized.h5\n",
      "469/469 [==============================] - 36s 75ms/step - loss: 0.6984 - accuracy: 0.5058 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "  2/469 [..............................] - ETA: 25s - loss: 0.7082 - accuracy: 0.3984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/469 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.5023\n",
      "Epoch 2: val_loss improved from 0.69381 to 0.69330, saving model to final_rnn_sentiment_model_optimized.h5\n",
      "469/469 [==============================] - 33s 71ms/step - loss: 0.6948 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.4965\n",
      "Epoch 3: val_loss improved from 0.69330 to 0.69318, saving model to final_rnn_sentiment_model_optimized.h5\n",
      "469/469 [==============================] - 33s 71ms/step - loss: 0.6941 - accuracy: 0.4964 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5013\n",
      "Epoch 4: val_loss improved from 0.69318 to 0.69317, saving model to final_rnn_sentiment_model_optimized.h5\n",
      "469/469 [==============================] - 33s 70ms/step - loss: 0.6936 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.4980\n",
      "Epoch 5: val_loss improved from 0.69317 to 0.69315, saving model to final_rnn_sentiment_model_optimized.h5\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 0.6935 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4959\n",
      "Epoch 6: val_loss did not improve from 0.69315\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.6933 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 7: val_loss did not improve from 0.69315\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5030\n",
      "Epoch 8: val_loss did not improve from 0.69315\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5049\n",
      "Epoch 9: val_loss did not improve from 0.69315\n",
      "469/469 [==============================] - 31s 67ms/step - loss: 0.6932 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4991\n",
      "Epoch 10: val_loss did not improve from 0.69315\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 0.6933 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#  Define the final model with the best hyperparameters\n",
    "final_model = Sequential()\n",
    "\n",
    "#  Embedding layer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "final_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))  # Embedding Dim: 128\n",
    "\n",
    "#  RNN Layer\n",
    "final_model.add(SimpleRNN(units=128, activation='relu', return_sequences=False))  # RNN Units: 128\n",
    "\n",
    "#  Regularization layers\n",
    "final_model.add(Dropout(0.2))  # Dropout Rate: 0.2\n",
    "final_model.add(BatchNormalization())\n",
    "\n",
    "# Dense Layer\n",
    "final_model.add(Dense(128, activation='relu'))\n",
    "final_model.add(Dropout(0.2))\n",
    "\n",
    "#  Output layer\n",
    "final_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#  Compile the model with optimized learning rate\n",
    "final_model.compile(optimizer=Adam(learning_rate=0.0001),  # Learning Rate: 0.0001\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "#  Callbacks\n",
    "checkpoint = ModelCheckpoint(\"final_rnn_sentiment_model_optimized.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "#  Train the model\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,          # Batch size\n",
    "    epochs=20,              # Train for 20 epochs\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3q9puMn87Dq0",
    "outputId": "a71f7e5e-8ed5-460b-e245-1f163ee33416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 7s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = final_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBmKD0qjGIrr"
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqRFeAJOGSVG"
   },
   "source": [
    "Positive sentiment (1) if >= 0.5\n",
    "\n",
    "Negative sentiment (0) if < 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVDQ5uRGuHAo",
    "outputId": "3b4dac35-f02d-4fe8-83b3-fe22a500a6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "#  Load the trained RNN model\n",
    "model = load_model(\"final_rnn_sentiment_model_optimized.h5\")\n",
    "\n",
    "#  Make predictions\n",
    "predictions = final_model.predict(X_test_padded)\n",
    "\n",
    "#  Convert probabilities to binary labels\n",
    "test_data['predicted_sentiment'] = (predictions >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXDIhVROuNtx"
   },
   "source": [
    "##  **Evaluate the Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBukDP7wuLsZ",
    "outputId": "a01b1d64-af26-4ba2-aa73-1186a1fbabe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Accuracy on New Test Data: 0.4333\n",
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60        26\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.43        60\n",
      "   macro avg       0.22      0.50      0.30        60\n",
      "weighted avg       0.19      0.43      0.26        60\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "\n",
      "[[26  0]\n",
      " [34  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#  Calculate accuracy\n",
    "accuracy = accuracy_score(test_data['sentiment_encoded'], test_data['predicted_sentiment'])\n",
    "print(f\"\\n Model Accuracy on New Test Data: {accuracy:.4f}\")\n",
    "\n",
    "#  Display a detailed classification report\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(test_data['sentiment_encoded'], test_data['predicted_sentiment']))\n",
    "\n",
    "#  Display confusion matrix\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(test_data['sentiment_encoded'], test_data['predicted_sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vzpxxylv6LU"
   },
   "source": [
    "# Hyperparameter Tuning again : MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzJtjUjcv9CT",
    "outputId": "6ad1af0a-4760-4e99-9ad8-5f3eb72f5664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8210 - accuracy: 0.5029\n",
      "Epoch 1: val_loss improved from inf to 0.77831, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 137s 285ms/step - loss: 0.8210 - accuracy: 0.5029 - val_loss: 0.7783 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.4964\n",
      "Epoch 2: val_loss improved from 0.77831 to 0.76827, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 127s 270ms/step - loss: 0.7893 - accuracy: 0.4964 - val_loss: 0.7683 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.5045\n",
      "Epoch 3: val_loss improved from 0.76827 to 0.75847, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.7738 - accuracy: 0.5045 - val_loss: 0.7585 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7652 - accuracy: 0.4965\n",
      "Epoch 4: val_loss improved from 0.75847 to 0.75226, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.7652 - accuracy: 0.4965 - val_loss: 0.7523 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.4995\n",
      "Epoch 5: val_loss improved from 0.75226 to 0.74765, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 123s 263ms/step - loss: 0.7584 - accuracy: 0.4995 - val_loss: 0.7477 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7519 - accuracy: 0.4996\n",
      "Epoch 6: val_loss improved from 0.74765 to 0.74051, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.7519 - accuracy: 0.4996 - val_loss: 0.7405 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.4998\n",
      "Epoch 7: val_loss improved from 0.74051 to 0.73541, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.7436 - accuracy: 0.4998 - val_loss: 0.7354 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.5020\n",
      "Epoch 8: val_loss improved from 0.73541 to 0.73099, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.7374 - accuracy: 0.5020 - val_loss: 0.7310 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7326 - accuracy: 0.5016\n",
      "Epoch 9: val_loss improved from 0.73099 to 0.72616, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.7326 - accuracy: 0.5016 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7277 - accuracy: 0.4981\n",
      "Epoch 10: val_loss improved from 0.72616 to 0.72202, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 126s 268ms/step - loss: 0.7277 - accuracy: 0.4981 - val_loss: 0.7220 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.5051\n",
      "Epoch 11: val_loss improved from 0.72202 to 0.71823, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 124s 265ms/step - loss: 0.7229 - accuracy: 0.5051 - val_loss: 0.7182 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7191 - accuracy: 0.5021\n",
      "Epoch 12: val_loss improved from 0.71823 to 0.71489, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 267ms/step - loss: 0.7191 - accuracy: 0.5021 - val_loss: 0.7149 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7170 - accuracy: 0.4958\n",
      "Epoch 13: val_loss improved from 0.71489 to 0.71194, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 124s 264ms/step - loss: 0.7170 - accuracy: 0.4958 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7132 - accuracy: 0.5016\n",
      "Epoch 14: val_loss improved from 0.71194 to 0.70949, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 126s 269ms/step - loss: 0.7132 - accuracy: 0.5016 - val_loss: 0.7095 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.4987\n",
      "Epoch 15: val_loss improved from 0.70949 to 0.70747, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 125s 266ms/step - loss: 0.7109 - accuracy: 0.4987 - val_loss: 0.7075 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.4952\n",
      "Epoch 16: val_loss improved from 0.70747 to 0.70584, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 127s 271ms/step - loss: 0.7089 - accuracy: 0.4952 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7069 - accuracy: 0.5032\n",
      "Epoch 17: val_loss improved from 0.70584 to 0.70450, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 127s 270ms/step - loss: 0.7069 - accuracy: 0.5032 - val_loss: 0.7045 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.5002\n",
      "Epoch 18: val_loss improved from 0.70450 to 0.70318, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 131s 279ms/step - loss: 0.7057 - accuracy: 0.5002 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.4980\n",
      "Epoch 19: val_loss improved from 0.70318 to 0.70220, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 129s 276ms/step - loss: 0.7042 - accuracy: 0.4980 - val_loss: 0.7022 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.4999\n",
      "Epoch 20: val_loss improved from 0.70220 to 0.70138, saving model to improved_rnn_sentiment_model.h5\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.7034 - accuracy: 0.4999 - val_loss: 0.7014 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5230\n",
      "Epoch 21: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 128s 274ms/step - loss: 0.6925 - accuracy: 0.5230 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7030 - accuracy: 0.4996\n",
      "Epoch 22: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 127s 272ms/step - loss: 0.7030 - accuracy: 0.4996 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7037 - accuracy: 0.4994\n",
      "Epoch 23: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 128s 272ms/step - loss: 0.7037 - accuracy: 0.4994 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.4991\n",
      "Epoch 24: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.7013 - accuracy: 0.4991 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.4995\n",
      "Epoch 25: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.7006 - accuracy: 0.4995 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.6995 - accuracy: 0.5008\n",
      "Epoch 26: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 129s 274ms/step - loss: 0.6995 - accuracy: 0.5008 - val_loss: nan - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.5033\n",
      "Epoch 27: val_loss did not improve from 0.70138\n",
      "469/469 [==============================] - 129s 275ms/step - loss: 0.6988 - accuracy: 0.5033 - val_loss: nan - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#  Define the improved RNN model\n",
    "improved_model = Sequential()\n",
    "\n",
    "#  Embedding layer\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "improved_model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len))\n",
    "\n",
    "#  Bidirectional RNN Layer\n",
    "improved_model.add(Bidirectional(SimpleRNN(units=128, activation='relu', return_sequences=True)))  # Bidirectional RNN\n",
    "improved_model.add(Dropout(0.3))\n",
    "improved_model.add(BatchNormalization())\n",
    "\n",
    "#  Additional RNN layer for deeper learning\n",
    "improved_model.add(SimpleRNN(units=64, activation='relu', return_sequences=False))\n",
    "improved_model.add(Dropout(0.3))\n",
    "improved_model.add(BatchNormalization())\n",
    "\n",
    "#  Dense Layer with L2 Regularization\n",
    "improved_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "improved_model.add(Dropout(0.3))\n",
    "\n",
    "#  Output layer\n",
    "improved_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#  Compile the model with Gradient Clipping\n",
    "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)  # Gradient clipping\n",
    "improved_model.compile(optimizer=optimizer,\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "#  Callbacks\n",
    "checkpoint = ModelCheckpoint(\"improved_rnn_sentiment_model.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)  # Increased patience\n",
    "\n",
    "#  Train the improved model\n",
    "history = improved_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=30,  # Train for more epochs\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVP2YZrCRUmh",
    "outputId": "6f79a512-e6b2-4c64-cdf1-9c7992bf1555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 17s 27ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Test Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = load_model('improved_rnn_sentiment_model.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RZmNtpYwANL",
    "outputId": "7120b5fc-68d1-4c9b-d4cb-0abfffa1ffae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the trained RNN model\n",
    "model = load_model(\"improved_rnn_sentiment_model.h5\")\n",
    "\n",
    "# Make predictions\n",
    "predictions2 = improved_model.predict(X_test_padded)\n",
    "\n",
    "# Convert probabilities to binary labels\n",
    "test_data['predicted_sentiment2'] = (predictions2 >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dG_WuyDdwIzt",
    "outputId": "667e2abc-c772-46d3-9f44-b5e298d1475f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Accuracy on New Test Data: 0.4333\n",
      "\n",
      " Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60        26\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.43        60\n",
      "   macro avg       0.22      0.50      0.30        60\n",
      "weighted avg       0.19      0.43      0.26        60\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "\n",
      "[[26  0]\n",
      " [34  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aniru\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_data['sentiment_encoded'], test_data['predicted_sentiment2'])\n",
    "print(f\"\\n Model Accuracy on New Test Data: {accuracy:.4f}\")\n",
    "\n",
    "# Display a detailed classification report\n",
    "print(\"\\n Classification Report:\\n\")\n",
    "print(classification_report(test_data['sentiment_encoded'], test_data['predicted_sentiment2']))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\n Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(test_data['sentiment_encoded'], test_data['predicted_sentiment2']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
